Index: attention.ipynb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\r\n \"cells\": [\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 1,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"all imports done\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"from letters_dataset import LettersDataset\\n\",\r\n    \"from seq2seq.byte_pair_encoding import Byte_Pair_Encoding\\n\",\r\n    \"from words_dataset import WordsDataset\\n\",\r\n    \"from torch.utils.data import Dataset, DataLoader, ConcatDataset\\n\",\r\n    \"import torch\\n\",\r\n    \"import torch.nn as nn\\n\",\r\n    \"import torch.optim as optim\\n\",\r\n    \"import numpy as np\\n\",\r\n    \"\\n\",\r\n    \"import random\\n\",\r\n    \"import math\\n\",\r\n    \"import time\\n\",\r\n    \"\\n\",\r\n    \"from train_collections import DS_ARABIC_LETTERS, DS_HARAKAT\\n\",\r\n    \"\\n\",\r\n    \"print(\\\"all imports done\\\")\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 2,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 3,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"class Encoder(nn.Module):\\n\",\r\n    \"    def __init__(self, input_dim, embedding_dim=128, hidden_dim=256, num_layers=1, dropout_probability=0.1):\\n\",\r\n    \"        super().__init__()\\n\",\r\n    \"        # TODO: replace with one hot encoding\\n\",\r\n    \"        self.embedding = nn.Embedding(input_dim, embedding_dim)\\n\",\r\n    \"        self.lstm_layer = nn.LSTM(\\n\",\r\n    \"            embedding_dim, hidden_dim, num_layers, dropout=dropout_probability, batch_first=True)\\n\",\r\n    \"\\n\",\r\n    \"        # Dropout layer to prevent over fitting (regularization)\\n\",\r\n    \"        # it randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\\n\",\r\n    \"        self.dropout = nn.Dropout(dropout_probability)\\n\",\r\n    \"\\n\",\r\n    \"    def forward(self, inputs):\\n\",\r\n    \"        # inputs = [inputs len, batch size]\\n\",\r\n    \"        embeddings = self.dropout(self.embedding(inputs))\\n\",\r\n    \"\\n\",\r\n    \"        # embedded = [inputs len, batch size, emb dim]\\n\",\r\n    \"        outputs, (hidden, cell) = self.lstm_layer(embeddings)\\n\",\r\n    \"\\n\",\r\n    \"        # outputs = [inputs len, batch size, hid dim * n directions]\\n\",\r\n    \"        # hidden = [n layers * n directions, batch size, hid dim]\\n\",\r\n    \"        # cell = [n layers * n directions, batch size, hid dim]\\n\",\r\n    \"        # outputs are always from the top hidden layer\\n\",\r\n    \"        return outputs,(hidden, cell)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 5,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"class Decoder(nn.Module):\\n\",\r\n    \"    def __init__(self, input_size, embedding_size, hidden_size, output_size, device='cuda'):\\n\",\r\n    \"        super().__init__()\\n\",\r\n    \"        self.input_size = input_size\\n\",\r\n    \"        self.hidden_size = hidden_size\\n\",\r\n    \"        self.output_size = output_size\\n\",\r\n    \"        self.device = device\\n\",\r\n    \"        self.embedding = nn.Embedding(input_size, embedding_size)\\n\",\r\n    \"        self.lstm = nn.LSTM(embedding_size+hidden_size, hidden_size, batch_first=True)\\n\",\r\n    \"        self.fc = nn.Linear(hidden_size, output_size)\\n\",\r\n    \"\\n\",\r\n    \"    def forward(self, x, context, h0, c0):\\n\",\r\n    \"        # print(\\\"from decoder forward\\\")\\n\",\r\n    \"        # print(x.shape)\\n\",\r\n    \"        embeddings = self.embedding(x)\\n\",\r\n    \"        # print(\\\"from decoder forward after embedding\\\")\\n\",\r\n    \"        # print(embeddings.shape)\\n\",\r\n    \"        lstm_input = torch.cat((embeddings, context), dim=2)\\n\",\r\n    \"        outs, (h1,c1) = self.lstm(lstm_input, (h0, c0))\\n\",\r\n    \"        # h is the output of the RNN\\n\",\r\n    \"        # hn is the hidden state of the last timestep\\n\",\r\n    \"        # cn is the cell state of the last timestep\\n\",\r\n    \"        scores = self.fc(outs)\\n\",\r\n    \"        return scores,(h1,c1)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 7,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"# %%Attention\\n\",\r\n    \"class AttentionSeq2Seq(nn.Module):\\n\",\r\n    \"    def __init__(self, encoder, decoder):\\n\",\r\n    \"        super().__init__()\\n\",\r\n    \"        self.encoder = encoder\\n\",\r\n    \"        self.decoder = decoder\\n\",\r\n    \"        self.softmax = nn.Softmax(dim=2)\\n\",\r\n    \"\\n\",\r\n    \"    def forward(self, encoder_inputs, decoder_inputs):\\n\",\r\n    \"        encoder_output, (encoder_hidden, encoder_cell) = self.encoder(encoder_inputs)\\n\",\r\n    \"        # print(\\\"hello\\\")\\n\",\r\n    \"        # add attention\\n\",\r\n    \"        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\\n\",\r\n    \"        sequence_length = decoder_inputs.size(1)\\n\",\r\n    \"        batch_size = decoder_inputs.size(0)\\n\",\r\n    \"        # final output of the decoder\\n\",\r\n    \"        # batch size * sequence length * output size\\n\",\r\n    \"        final_output = torch.zeros(\\n\",\r\n    \"            batch_size, sequence_length, self.decoder.output_size, device=device)\\n\",\r\n    \"        for i in range(sequence_length):\\n\",\r\n    \"            attention_weights = self.calculate_attention_weights(encoder_output, decoder_hidden)\\n\",\r\n    \"            attention_vectors = attention_weights * encoder_output\\n\",\r\n    \"            context_vector = torch.sum(attention_vectors, dim=1, keepdim=True)\\n\",\r\n    \"            scores ,(decoder_hidden, decoder_cell) = self.decoder(decoder_inputs[:, i:i+1], context_vector, decoder_hidden, decoder_cell)\\n\",\r\n    \"            final_output[:, i:i+1, :] = scores\\n\",\r\n    \"        return final_output\\n\",\r\n    \"\\n\",\r\n    \"    def calculate_attention_weights(self, encoder_output, decoder_hidden):\\n\",\r\n    \"        # encoder output: [batch size, seq len, hidden size]\\n\",\r\n    \"        # decoder hidden: [1, batch size, hidden size]\\n\",\r\n    \"        # attention weights: [batch size, seq len, 1]\\n\",\r\n    \"        decoder_hidden_permuted = decoder_hidden.permute(1, 2, 0)\\n\",\r\n    \"        attention_weights = torch.bmm(encoder_output, decoder_hidden_permuted)\\n\",\r\n    \"        attention_weights = self.softmax(attention_weights)\\n\",\r\n    \"        return attention_weights\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 9,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"decoder_dim_vocab = len(DS_ARABIC_LETTERS)\\n\",\r\n    \"decoder_dim_out = len(DS_HARAKAT) + 2  # harakat\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 11,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"embedding_dim = 64\\n\",\r\n    \"n_epochs = 5\\n\",\r\n    \"batch_size = 64\\n\",\r\n    \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 13,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"bpe = Byte_Pair_Encoding(450)\\n\",\r\n    \"bpe.train(\\\"./clean_out/merged.txt\\\")\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 14,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"w = 495\\n\",\r\n      \"adham\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"decodor_dataset = LettersDataset(\\n\",\r\n    \"    \\\"./clean_out/X.csv\\\", \\\"./clean_out/Y.csv\\\", device=device)\\n\",\r\n    \"encoder_dataset = WordsDataset(\\n\",\r\n    \"    \\\"./clean_out/X_words.txt\\\", device=device, tokenizer=bpe)\\n\",\r\n    \"print(\\\"adham\\\")\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 15,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"torch.Size([64, 450])\\n\",\r\n      \"torch.Size([64, 495])\\n\",\r\n      \"torch.Size([64, 495])\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"class CombinedDataset(Dataset):\\n\",\r\n    \"    def __init__(self, words_dataset, letters_dataset):\\n\",\r\n    \"        self.words_dataset = words_dataset\\n\",\r\n    \"        self.letters_dataset = letters_dataset\\n\",\r\n    \"\\n\",\r\n    \"        # Ensure both datasets are of the same size\\n\",\r\n    \"        assert len(words_dataset) == len(\\n\",\r\n    \"            letters_dataset), \\\"Datasets must be of the same size\\\"\\n\",\r\n    \"\\n\",\r\n    \"    def __len__(self):\\n\",\r\n    \"        return len(self.words_dataset)\\n\",\r\n    \"\\n\",\r\n    \"    def __getitem__(self, idx):\\n\",\r\n    \"        word = self.words_dataset[idx]\\n\",\r\n    \"        letters, letter_tashkeel = self.letters_dataset[idx]\\n\",\r\n    \"\\n\",\r\n    \"        # Combine or process the features as needed for your model\\n\",\r\n    \"        # This can vary depending on how your seq2seq model is set up\\n\",\r\n    \"\\n\",\r\n    \"        return word, letters, letter_tashkeel\\n\",\r\n    \"    \\n\",\r\n    \"merged_set = CombinedDataset(encoder_dataset, decodor_dataset)\\n\",\r\n    \"\\n\",\r\n    \"seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\\n\",\r\n    \"\\n\",\r\n    \"sample = next(iter(seq2seq_loader))\\n\",\r\n    \"print(sample[0].shape)\\n\",\r\n    \"print(sample[1].shape)\\n\",\r\n    \"print(sample[2].shape)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 16,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"AttentionSeq2Seq(\\n\",\r\n      \"  (encoder): Encoder(\\n\",\r\n      \"    (embedding): Embedding(30000, 128)\\n\",\r\n      \"    (lstm_layer): LSTM(128, 128, batch_first=True)\\n\",\r\n      \"    (dropout): Dropout(p=0, inplace=False)\\n\",\r\n      \"  )\\n\",\r\n      \"  (decoder): Decoder(\\n\",\r\n      \"    (embedding): Embedding(60, 128)\\n\",\r\n      \"    (lstm): LSTM(256, 128, batch_first=True)\\n\",\r\n      \"    (fc): Linear(in_features=128, out_features=17, bias=True)\\n\",\r\n      \"  )\\n\",\r\n      \"  (softmax): Softmax(dim=2)\\n\",\r\n      \")\\n\",\r\n      \"Number of batches: 2590\\n\",\r\n      \"Epoch 0, batch 0: Loss = 3.0025\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"enc_model = Encoder(\\n\",\r\n    \"    encoder_dataset.bpe.tokenizer.get_vocab_size(), hidden_dim=128, num_layers=1, dropout_probability=0)\\n\",\r\n    \"\\n\",\r\n    \"dec_model = Decoder(decoder_dim_vocab, embedding_size=128,\\n\",\r\n    \"                    hidden_size=128, output_size=decoder_dim_out, device=device.type)\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"model = AttentionSeq2Seq(encoder=enc_model, decoder=dec_model).to(device)\\n\",\r\n    \"print(model)\\n\",\r\n    \"optimizer = optim.Adam(model.parameters(), lr=1e-3)\\n\",\r\n    \"loss_fn = nn.CrossEntropyLoss()\\n\",\r\n    \"num_batches = len(seq2seq_loader)\\n\",\r\n    \"print(\\\"Number of batches:\\\", num_batches)\\n\",\r\n    \"best_model = None\\n\",\r\n    \"best_loss = np.inf\\n\",\r\n    \"for epoch in range(n_epochs):\\n\",\r\n    \"    model.train()\\n\",\r\n    \"    for i, (X_encoder, X_decoder, Y_batch) in enumerate(seq2seq_loader):\\n\",\r\n    \"        y_pred = ''\\n\",\r\n    \"        y_pred = model(X_encoder, X_decoder)\\n\",\r\n    \"        y_pred = y_pred.transpose(1, 2)\\n\",\r\n    \"        # print(y_pred.shape)\\n\",\r\n    \"        # print(y_batch.shape)\\n\",\r\n    \"        loss = loss_fn(y_pred, Y_batch)\\n\",\r\n    \"        optimizer.zero_grad()\\n\",\r\n    \"        loss.backward()\\n\",\r\n    \"        optimizer.step()\\n\",\r\n    \"        if i % 100 == 0:\\n\",\r\n    \"            print(\\\"Epoch %d, batch %d: Loss = %.4f\\\" % (epoch, i, loss))\\n\",\r\n    \"\\n\",\r\n    \"    # Validation\\n\",\r\n    \"    model.eval()\\n\",\r\n    \"    loss = 0\\n\",\r\n    \"    with torch.no_grad():\\n\",\r\n    \"        for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\\n\",\r\n    \"            y_pred = model(X_encoder, X_decoder)\\n\",\r\n    \"            y_pred = y_pred.transpose(1, 2)\\n\",\r\n    \"\\n\",\r\n    \"            loss += loss_fn(y_pred, Y_batch)\\n\",\r\n    \"        if loss < best_loss:\\n\",\r\n    \"            best_loss = loss\\n\",\r\n    \"            best_model = model.state_dict()\\n\",\r\n    \"        print(\\\"Epoch %d: Cross-entropy: %.4f\\\" % (epoch, loss))\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"val_dataset = LettersDataset(\\n\",\r\n    \"    './clean_out/X_val.csv', './clean_out/y_val.csv', device=device)\\n\",\r\n    \"val_words_dataset = WordsDataset(\\n\",\r\n    \"    './clean_out/X_words_val.txt', device=device, tokenizer=bpe)\\n\",\r\n    \"val_merged = CombinedDataset(val_words_dataset, val_dataset)\\n\",\r\n    \"seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"model.eval()\\n\",\r\n    \"correct = 0\\n\",\r\n    \"total = 0\\n\",\r\n    \"\\n\",\r\n    \"with torch.no_grad():\\n\",\r\n    \"    for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\\n\",\r\n    \"        is_padding = (X_decoder == val_dataset.char_encoder.get_pad_token())\\n\",\r\n    \"        y_pred = model(X_encoder, X_decoder)\\n\",\r\n    \"        y_pred = y_pred.transpose(1, 2)\\n\",\r\n    \"        _, predicted = torch.max(y_pred.data, 1)\\n\",\r\n    \"        # Count only non-padding characters\\n\",\r\n    \"        total += torch.sum(~is_padding).item()\\n\",\r\n    \"\\n\",\r\n    \"        # Count correct predictions\\n\",\r\n    \"        correct += torch.sum((predicted == Y_batch) & (~is_padding)).item()\\n\",\r\n    \"print(\\\"Accuracy: %.2f%%\\\" % (100 * correct / total))\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": []\r\n  }\r\n ],\r\n \"metadata\": {\r\n  \"kernelspec\": {\r\n   \"display_name\": \"Python 3\",\r\n   \"language\": \"python\",\r\n   \"name\": \"python3\"\r\n  },\r\n  \"language_info\": {\r\n   \"codemirror_mode\": {\r\n    \"name\": \"ipython\",\r\n    \"version\": 3\r\n   },\r\n   \"file_extension\": \".py\",\r\n   \"mimetype\": \"text/x-python\",\r\n   \"name\": \"python\",\r\n   \"nbconvert_exporter\": \"python\",\r\n   \"pygments_lexer\": \"ipython3\",\r\n   \"version\": \"3.10.7\"\r\n  }\r\n },\r\n \"nbformat\": 4,\r\n \"nbformat_minor\": 2\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/attention.ipynb b/attention.ipynb
--- a/attention.ipynb	(revision 1812371599fb00564644645c1b5dd2f839fba7af)
+++ b/attention.ipynb	(date 1702942170776)
@@ -274,6 +274,19 @@
       "Number of batches: 2590\n",
       "Epoch 0, batch 0: Loss = 3.0025\n"
      ]
+    },
+    {
+     "ename": "KeyboardInterrupt",
+     "evalue": "",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
+      "Cell \u001b[1;32mIn [16], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, Y_batch)\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
+      "File \u001b[1;32mc:\\Users\\adham ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[1;32mc:\\Users\\adham ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
+      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
+     ]
     }
    ],
    "source": [
Index: main.ipynb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\r\n \"cells\": [\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 1,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"from letters_dataset import LettersDataset\\n\",\r\n    \"from seq2seq.byte_pair_encoding import Byte_Pair_Encoding\\n\",\r\n    \"from words_dataset import WordsDataset\\n\",\r\n    \"from torch.utils.data import Dataset, DataLoader, ConcatDataset\\n\",\r\n    \"import torch\\n\",\r\n    \"import torch.nn as nn\\n\",\r\n    \"import torch.optim as optim\\n\",\r\n    \"import numpy as np\\n\",\r\n    \"\\n\",\r\n    \"import random\\n\",\r\n    \"import math\\n\",\r\n    \"import time\\n\",\r\n    \"\\n\",\r\n    \"from train_collections import DS_ARABIC_LETTERS, DS_HARAKAT\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 2,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 3,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"class Encoder(nn.Module):\\n\",\r\n    \"    def __init__(self, input_dim, embedding_dim=128, hidden_dim=256, num_layers=1, dropout_probability=0.1):\\n\",\r\n    \"        super().__init__()\\n\",\r\n    \"        # TODO: replace with one hot encoding\\n\",\r\n    \"        self.embedding = nn.Embedding(input_dim, embedding_dim)\\n\",\r\n    \"        self.lstm_layer = nn.LSTM(\\n\",\r\n    \"            embedding_dim, hidden_dim, num_layers, dropout=dropout_probability, batch_first=True)\\n\",\r\n    \"\\n\",\r\n    \"        # Dropout layer to prevent over fitting (regularization)\\n\",\r\n    \"        # it randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\\n\",\r\n    \"        self.dropout = nn.Dropout(dropout_probability)\\n\",\r\n    \"\\n\",\r\n    \"    def forward(self, inputs):\\n\",\r\n    \"        # inputs = [inputs len, batch size]\\n\",\r\n    \"        embeddings = self.dropout(self.embedding(inputs))\\n\",\r\n    \"\\n\",\r\n    \"        # embedded = [inputs len, batch size, emb dim]\\n\",\r\n    \"        outputs, (hidden, cell) = self.lstm_layer(embeddings)\\n\",\r\n    \"\\n\",\r\n    \"        # outputs = [inputs len, batch size, hid dim * n directions]\\n\",\r\n    \"        # hidden = [n layers * n directions, batch size, hid dim]\\n\",\r\n    \"        # cell = [n layers * n directions, batch size, hid dim]\\n\",\r\n    \"        # outputs are always from the top hidden layer\\n\",\r\n    \"        return hidden, cell\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 4,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"class Decoder(nn.Module):\\n\",\r\n    \"    def __init__(self, input_size, embedding_size, hidden_size, output_size, device='cuda'):\\n\",\r\n    \"        super().__init__()\\n\",\r\n    \"        self.embedding = nn.Embedding(input_size, embedding_size)\\n\",\r\n    \"        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\\n\",\r\n    \"        self.fc = nn.Linear(hidden_size, output_size)\\n\",\r\n    \"\\n\",\r\n    \"    def forward(self, x, h0, c0):\\n\",\r\n    \"        # print(\\\"from decoder forward\\\")\\n\",\r\n    \"        # print(x.shape)\\n\",\r\n    \"        embeddings = self.embedding(x)\\n\",\r\n    \"        # print(\\\"from decoder forward after embedding\\\")\\n\",\r\n    \"        # print(embeddings.shape)\\n\",\r\n    \"        outs, _ = self.lstm(embeddings, (h0, c0))\\n\",\r\n    \"        # h is the output of the RNN\\n\",\r\n    \"        # hn is the hidden state of the last timestep\\n\",\r\n    \"        # cn is the cell state of the last timestep\\n\",\r\n    \"        scores = self.fc(outs)\\n\",\r\n    \"        return scores\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 5,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"class Seq2Seq(nn.Module):\\n\",\r\n    \"    def __init__(self, encoder, decoder):\\n\",\r\n    \"        super().__init__()\\n\",\r\n    \"        self.encoder = encoder\\n\",\r\n    \"        self.decoder = decoder\\n\",\r\n    \"\\n\",\r\n    \"    def forward(self, encoder_inputs, decoder_inputs):\\n\",\r\n    \"        encoder_hidden, encoder_cell = self.encoder(encoder_inputs)\\n\",\r\n    \"        decoder_output = self.decoder(\\n\",\r\n    \"            decoder_inputs, encoder_hidden, encoder_cell)\\n\",\r\n    \"        return decoder_output\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 6,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"decoder_dim_vocab = len(DS_ARABIC_LETTERS)\\n\",\r\n    \"decoder_dim_out = len(DS_HARAKAT) + 2  # harakat\\n\",\r\n    \"\\n\",\r\n    \"# encoder_dim_vocab = #tokens\\n\",\r\n    \"\\n\",\r\n    \"embedding_dim = 64\\n\",\r\n    \"n_epochs = 5\\n\",\r\n    \"batch_size = 64\\n\",\r\n    \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 7,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"bpe = Byte_Pair_Encoding(450)\\n\",\r\n    \"bpe.train(\\\"./clean_out/merged.txt\\\")\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 8,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"w = 495\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"decodor_dataset = LettersDataset(\\n\",\r\n    \"    \\\"./clean_out/X.csv\\\", \\\"./clean_out/Y.csv\\\", device=device)\\n\",\r\n    \"encoder_dataset = WordsDataset(\\n\",\r\n    \"    \\\"./clean_out/X_words.txt\\\", device=device, tokenizer=bpe)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 9,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"torch.Size([64, 450])\\n\",\r\n      \"torch.Size([64, 495])\\n\",\r\n      \"torch.Size([64, 495])\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"class CombinedDataset(Dataset):\\n\",\r\n    \"    def __init__(self, words_dataset, letters_dataset):\\n\",\r\n    \"        self.words_dataset = words_dataset\\n\",\r\n    \"        self.letters_dataset = letters_dataset\\n\",\r\n    \"\\n\",\r\n    \"        # Ensure both datasets are of the same size\\n\",\r\n    \"        assert len(words_dataset) == len(\\n\",\r\n    \"            letters_dataset), \\\"Datasets must be of the same size\\\"\\n\",\r\n    \"\\n\",\r\n    \"    def __len__(self):\\n\",\r\n    \"        return len(self.words_dataset)\\n\",\r\n    \"\\n\",\r\n    \"    def __getitem__(self, idx):\\n\",\r\n    \"        word = self.words_dataset[idx]\\n\",\r\n    \"        letters, letter_tashkeel = self.letters_dataset[idx]\\n\",\r\n    \"\\n\",\r\n    \"        # Combine or process the features as needed for your model\\n\",\r\n    \"        # This can vary depending on how your seq2seq model is set up\\n\",\r\n    \"\\n\",\r\n    \"        return word, letters, letter_tashkeel\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"merged_set = CombinedDataset(encoder_dataset, decodor_dataset)\\n\",\r\n    \"\\n\",\r\n    \"seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\\n\",\r\n    \"\\n\",\r\n    \"sample = next(iter(seq2seq_loader))\\n\",\r\n    \"print(sample[0].shape)\\n\",\r\n    \"print(sample[1].shape)\\n\",\r\n    \"print(sample[2].shape)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 10,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stdout\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"Seq2Seq(\\n\",\r\n      \"  (encoder): Encoder(\\n\",\r\n      \"    (embedding): Embedding(30000, 128)\\n\",\r\n      \"    (lstm_layer): LSTM(128, 128, batch_first=True)\\n\",\r\n      \"    (dropout): Dropout(p=0, inplace=False)\\n\",\r\n      \"  )\\n\",\r\n      \"  (decoder): Decoder(\\n\",\r\n      \"    (embedding): Embedding(60, 128)\\n\",\r\n      \"    (lstm): LSTM(128, 128, batch_first=True)\\n\",\r\n      \"    (fc): Linear(in_features=128, out_features=17, bias=True)\\n\",\r\n      \"  )\\n\",\r\n      \")\\n\",\r\n      \"Number of batches: 2590\\n\",\r\n      \"Epoch 0, batch 0: Loss = 3.0016\\n\",\r\n      \"Epoch 0, batch 100: Loss = 0.2178\\n\",\r\n      \"Epoch 0, batch 200: Loss = 0.1094\\n\",\r\n      \"Epoch 0, batch 300: Loss = 0.0981\\n\",\r\n      \"Epoch 0, batch 400: Loss = 0.1038\\n\",\r\n      \"Epoch 0, batch 500: Loss = 0.0906\\n\",\r\n      \"Epoch 0, batch 600: Loss = 0.0585\\n\",\r\n      \"Epoch 0, batch 700: Loss = 0.1065\\n\",\r\n      \"Epoch 0, batch 800: Loss = 0.0848\\n\",\r\n      \"Epoch 0, batch 900: Loss = 0.0539\\n\",\r\n      \"Epoch 0, batch 1000: Loss = 0.0959\\n\",\r\n      \"Epoch 0, batch 1100: Loss = 0.0649\\n\",\r\n      \"Epoch 0, batch 1200: Loss = 0.0769\\n\",\r\n      \"Epoch 0, batch 1300: Loss = 0.0797\\n\",\r\n      \"Epoch 0, batch 1400: Loss = 0.0884\\n\",\r\n      \"Epoch 0, batch 1500: Loss = 0.0803\\n\",\r\n      \"Epoch 0, batch 1600: Loss = 0.0982\\n\",\r\n      \"Epoch 0, batch 1700: Loss = 0.0610\\n\",\r\n      \"Epoch 0, batch 1800: Loss = 0.0705\\n\",\r\n      \"Epoch 0, batch 1900: Loss = 0.0611\\n\",\r\n      \"Epoch 0, batch 2000: Loss = 0.0577\\n\",\r\n      \"Epoch 0, batch 2100: Loss = 0.0707\\n\",\r\n      \"Epoch 0, batch 2200: Loss = 0.0564\\n\",\r\n      \"Epoch 0, batch 2300: Loss = 0.0647\\n\",\r\n      \"Epoch 0, batch 2400: Loss = 0.0706\\n\",\r\n      \"Epoch 0, batch 2500: Loss = 0.0665\\n\",\r\n      \"Epoch 0: Cross-entropy: 164.1404\\n\",\r\n      \"Epoch 1, batch 0: Loss = 0.0550\\n\",\r\n      \"Epoch 1, batch 100: Loss = 0.0635\\n\",\r\n      \"Epoch 1, batch 200: Loss = 0.0611\\n\",\r\n      \"Epoch 1, batch 300: Loss = 0.0476\\n\",\r\n      \"Epoch 1, batch 400: Loss = 0.0477\\n\",\r\n      \"Epoch 1, batch 500: Loss = 0.0584\\n\",\r\n      \"Epoch 1, batch 600: Loss = 0.0543\\n\",\r\n      \"Epoch 1, batch 700: Loss = 0.0652\\n\",\r\n      \"Epoch 1, batch 800: Loss = 0.0565\\n\",\r\n      \"Epoch 1, batch 900: Loss = 0.0414\\n\",\r\n      \"Epoch 1, batch 1000: Loss = 0.0700\\n\",\r\n      \"Epoch 1, batch 1100: Loss = 0.0671\\n\",\r\n      \"Epoch 1, batch 1200: Loss = 0.0617\\n\",\r\n      \"Epoch 1, batch 1300: Loss = 0.0508\\n\",\r\n      \"Epoch 1, batch 1400: Loss = 0.0604\\n\",\r\n      \"Epoch 1, batch 1500: Loss = 0.0478\\n\",\r\n      \"Epoch 1, batch 1600: Loss = 0.0510\\n\",\r\n      \"Epoch 1, batch 1700: Loss = 0.0498\\n\",\r\n      \"Epoch 1, batch 1800: Loss = 0.0603\\n\",\r\n      \"Epoch 1, batch 1900: Loss = 0.0753\\n\",\r\n      \"Epoch 1, batch 2000: Loss = 0.0557\\n\",\r\n      \"Epoch 1, batch 2100: Loss = 0.0746\\n\",\r\n      \"Epoch 1, batch 2200: Loss = 0.0494\\n\",\r\n      \"Epoch 1, batch 2300: Loss = 0.0637\\n\",\r\n      \"Epoch 1, batch 2400: Loss = 0.0440\\n\",\r\n      \"Epoch 1, batch 2500: Loss = 0.0460\\n\",\r\n      \"Epoch 1: Cross-entropy: 145.7660\\n\",\r\n      \"Epoch 2, batch 0: Loss = 0.0554\\n\",\r\n      \"Epoch 2, batch 100: Loss = 0.0667\\n\",\r\n      \"Epoch 2, batch 200: Loss = 0.0461\\n\",\r\n      \"Epoch 2, batch 300: Loss = 0.0570\\n\",\r\n      \"Epoch 2, batch 400: Loss = 0.0378\\n\",\r\n      \"Epoch 2, batch 500: Loss = 0.0602\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"enc_model = Encoder(\\n\",\r\n    \"    encoder_dataset.bpe.tokenizer.get_vocab_size(), hidden_dim=128, num_layers=1, dropout_probability=0)\\n\",\r\n    \"\\n\",\r\n    \"dec_model = Decoder(decoder_dim_vocab, embedding_size=128,\\n\",\r\n    \"                    hidden_size=128, output_size=decoder_dim_out, device=device.type)\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"model = Seq2Seq(encoder=enc_model, decoder=dec_model).to(device)\\n\",\r\n    \"print(model)\\n\",\r\n    \"optimizer = optim.Adam(model.parameters(), lr=1e-3)\\n\",\r\n    \"loss_fn = nn.CrossEntropyLoss()\\n\",\r\n    \"num_batches = len(seq2seq_loader)\\n\",\r\n    \"print(\\\"Number of batches:\\\", num_batches)\\n\",\r\n    \"best_model = None\\n\",\r\n    \"best_loss = np.inf\\n\",\r\n    \"for epoch in range(n_epochs):\\n\",\r\n    \"    model.train()\\n\",\r\n    \"    for i, (X_encoder, X_decoder, Y_batch) in enumerate(seq2seq_loader):\\n\",\r\n    \"        y_pred = ''\\n\",\r\n    \"        y_pred = model(X_encoder, X_decoder)\\n\",\r\n    \"        y_pred = y_pred.transpose(1, 2)\\n\",\r\n    \"        # print(y_pred.shape)\\n\",\r\n    \"        # print(y_batch.shape)\\n\",\r\n    \"        loss = loss_fn(y_pred, Y_batch)\\n\",\r\n    \"        optimizer.zero_grad()\\n\",\r\n    \"        loss.backward()\\n\",\r\n    \"        optimizer.step()\\n\",\r\n    \"        if i % 100 == 0:\\n\",\r\n    \"            print(\\\"Epoch %d, batch %d: Loss = %.4f\\\" % (epoch, i, loss))\\n\",\r\n    \"\\n\",\r\n    \"    # Validation\\n\",\r\n    \"    model.eval()\\n\",\r\n    \"    loss = 0\\n\",\r\n    \"    with torch.no_grad():\\n\",\r\n    \"        for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\\n\",\r\n    \"            y_pred = model(X_encoder, X_decoder)\\n\",\r\n    \"            y_pred = y_pred.transpose(1, 2)\\n\",\r\n    \"\\n\",\r\n    \"            loss += loss_fn(y_pred, Y_batch)\\n\",\r\n    \"        if loss < best_loss:\\n\",\r\n    \"            best_loss = loss\\n\",\r\n    \"            best_model = model.state_dict()\\n\",\r\n    \"        print(\\\"Epoch %d: Cross-entropy: %.4f\\\" % (epoch, loss))\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"val_dataset = LettersDataset(\\n\",\r\n    \"    'clean_out/X_val.csv', 'clean_out/y_val.csv', device=device)\\n\",\r\n    \"val_words_dataset = WordsDataset(\\n\",\r\n    \"    'clean_out/X_words_val.txt', device=device, tokenizer=bpe)\\n\",\r\n    \"val_merged = CombinedDataset(val_words_dataset, val_dataset)\\n\",\r\n    \"seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\\n\",\r\n    \"\\n\",\r\n    \"# evaluaate accuracy on validation set\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"model.eval()\\n\",\r\n    \"correct = 0\\n\",\r\n    \"total = 0\\n\",\r\n    \"\\n\",\r\n    \"with torch.no_grad():\\n\",\r\n    \"    for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\\n\",\r\n    \"        is_padding = (X_decoder == val_dataset.char_encoder.get_pad_token())\\n\",\r\n    \"        y_pred = model(X_encoder, X_decoder)\\n\",\r\n    \"        y_pred = y_pred.transpose(1, 2)\\n\",\r\n    \"        _, predicted = torch.max(y_pred.data, 1)\\n\",\r\n    \"        # Count only non-padding characters\\n\",\r\n    \"        total += torch.sum(~is_padding).item()\\n\",\r\n    \"\\n\",\r\n    \"        # Count correct predictions\\n\",\r\n    \"        correct += torch.sum((predicted == Y_batch) & (~is_padding)).item()\\n\",\r\n    \"print(\\\"Accuracy: %.2f%%\\\" % (100 * correct / total))\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": []\r\n  }\r\n ],\r\n \"metadata\": {\r\n  \"kernelspec\": {\r\n   \"display_name\": \"Python 3\",\r\n   \"language\": \"python\",\r\n   \"name\": \"python3\"\r\n  },\r\n  \"language_info\": {\r\n   \"codemirror_mode\": {\r\n    \"name\": \"ipython\",\r\n    \"version\": 3\r\n   },\r\n   \"file_extension\": \".py\",\r\n   \"mimetype\": \"text/x-python\",\r\n   \"name\": \"python\",\r\n   \"nbconvert_exporter\": \"python\",\r\n   \"pygments_lexer\": \"ipython3\",\r\n   \"version\": \"3.10.7\"\r\n  }\r\n },\r\n \"nbformat\": 4,\r\n \"nbformat_minor\": 2\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.ipynb b/main.ipynb
--- a/main.ipynb	(revision 1812371599fb00564644645c1b5dd2f839fba7af)
+++ b/main.ipynb	(date 1702948551265)
@@ -115,8 +115,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "decoder_dim_vocab = len(DS_ARABIC_LETTERS)\n",
-    "decoder_dim_out = len(DS_HARAKAT) + 2  # harakat\n",
+    "encoder_dim_vocab = len(DS_ARABIC_LETTERS)\n",
+    "decoder_dim_vocab = len(DS_HARAKAT)\n",
     "\n",
     "# encoder_dim_vocab = #tokens\n",
     "\n",
@@ -127,16 +127,6 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 7,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "bpe = Byte_Pair_Encoding(450)\n",
-    "bpe.train(\"./clean_out/merged.txt\")"
-   ]
-  },
-  {
    "cell_type": "code",
    "execution_count": 8,
    "metadata": {},
@@ -151,57 +141,7 @@
    ],
    "source": [
     "decodor_dataset = LettersDataset(\n",
-    "    \"./clean_out/X.csv\", \"./clean_out/Y.csv\", device=device)\n",
-    "encoder_dataset = WordsDataset(\n",
-    "    \"./clean_out/X_words.txt\", device=device, tokenizer=bpe)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 9,
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "torch.Size([64, 450])\n",
-      "torch.Size([64, 495])\n",
-      "torch.Size([64, 495])\n"
-     ]
-    }
-   ],
-   "source": [
-    "class CombinedDataset(Dataset):\n",
-    "    def __init__(self, words_dataset, letters_dataset):\n",
-    "        self.words_dataset = words_dataset\n",
-    "        self.letters_dataset = letters_dataset\n",
-    "\n",
-    "        # Ensure both datasets are of the same size\n",
-    "        assert len(words_dataset) == len(\n",
-    "            letters_dataset), \"Datasets must be of the same size\"\n",
-    "\n",
-    "    def __len__(self):\n",
-    "        return len(self.words_dataset)\n",
-    "\n",
-    "    def __getitem__(self, idx):\n",
-    "        word = self.words_dataset[idx]\n",
-    "        letters, letter_tashkeel = self.letters_dataset[idx]\n",
-    "\n",
-    "        # Combine or process the features as needed for your model\n",
-    "        # This can vary depending on how your seq2seq model is set up\n",
-    "\n",
-    "        return word, letters, letter_tashkeel\n",
-    "\n",
-    "\n",
-    "merged_set = CombinedDataset(encoder_dataset, decodor_dataset)\n",
-    "\n",
-    "seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\n",
-    "\n",
-    "sample = next(iter(seq2seq_loader))\n",
-    "print(sample[0].shape)\n",
-    "print(sample[1].shape)\n",
-    "print(sample[2].shape)"
+    "    \"./clean_out/X.csv\", \"./clean_out/Y.csv\", device=device)"
    ]
   },
   {
@@ -285,13 +225,33 @@
       "Epoch 2, batch 200: Loss = 0.0461\n",
       "Epoch 2, batch 300: Loss = 0.0570\n",
       "Epoch 2, batch 400: Loss = 0.0378\n",
-      "Epoch 2, batch 500: Loss = 0.0602\n"
+      "Epoch 2, batch 500: Loss = 0.0602\n",
+      "Epoch 2, batch 600: Loss = 0.0559\n",
+      "Epoch 2, batch 700: Loss = 0.0468\n",
+      "Epoch 2, batch 800: Loss = 0.0496\n",
+      "Epoch 2, batch 900: Loss = 0.0601\n",
+      "Epoch 2, batch 1000: Loss = 0.0811\n",
+      "Epoch 2, batch 1100: Loss = 0.0804\n",
+      "Epoch 2, batch 1200: Loss = 0.0513\n",
+      "Epoch 2, batch 1300: Loss = 0.0450\n",
+      "Epoch 2, batch 1400: Loss = 0.0611\n",
+      "Epoch 2, batch 1500: Loss = 0.0523\n",
+      "Epoch 2, batch 1600: Loss = 0.0498\n",
+      "Epoch 2, batch 1700: Loss = 0.0562\n",
+      "Epoch 2, batch 1800: Loss = 0.0591\n",
+      "Epoch 2, batch 1900: Loss = 0.0524\n",
+      "Epoch 2, batch 2000: Loss = 0.0615\n",
+      "Epoch 2, batch 2100: Loss = 0.0489\n",
+      "Epoch 2, batch 2200: Loss = 0.0509\n",
+      "Epoch 2, batch 2300: Loss = 0.0581\n",
+      "Epoch 2, batch 2400: Loss = 0.0480\n",
+      "Epoch 2, batch 2500: Loss = 0.0509\n"
      ]
     }
    ],
    "source": [
     "enc_model = Encoder(\n",
-    "    encoder_dataset.bpe.tokenizer.get_vocab_size(), hidden_dim=128, num_layers=1, dropout_probability=0)\n",
+    "    , hidden_dim=128, num_layers=1, dropout_probability=0)\n",
     "\n",
     "dec_model = Decoder(decoder_dim_vocab, embedding_size=128,\n",
     "                    hidden_size=128, output_size=decoder_dim_out, device=device.type)\n",
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"AutoImportSettings\">\r\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\r\n  </component>\r\n  <component name=\"ChangeListManager\">\r\n    <list default=\"true\" id=\"45d69a52-e93d-4b59-9786-d3bacb09f552\" name=\"Changes\" comment=\"add attention mechanism\">\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/inspectionProfiles/profiles_settings.xml\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/misc.xml\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/modules.xml\" beforeDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/vcs.xml\" beforeDir=\"false\" />\r\n    </list>\r\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\r\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\r\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\r\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\r\n  </component>\r\n  <component name=\"FileTemplateManagerImpl\">\r\n    <option name=\"RECENT_TEMPLATES\">\r\n      <list>\r\n        <option value=\"Python Script\" />\r\n      </list>\r\n    </option>\r\n  </component>\r\n  <component name=\"Git.Settings\">\r\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\r\n      <map>\r\n        <entry key=\"$PROJECT_DIR$\" value=\"attention\" />\r\n      </map>\r\n    </option>\r\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\r\n  </component>\r\n  <component name=\"MarkdownSettingsMigration\">\r\n    <option name=\"stateVersion\" value=\"1\" />\r\n  </component>\r\n  <component name=\"ProjectColorInfo\">{\r\n  &quot;associatedIndex&quot;: 2\r\n}</component>\r\n  <component name=\"ProjectId\" id=\"2Zi13h5PLwqQJ06j8mne5leIPYH\" />\r\n  <component name=\"ProjectLevelVcsManager\" settingsEditedManually=\"true\" />\r\n  <component name=\"ProjectViewState\">\r\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\r\n    <option name=\"showLibraryContents\" value=\"true\" />\r\n  </component>\r\n  <component name=\"PropertiesComponent\"><![CDATA[{\r\n  \"keyToString\": {\r\n    \"RunOnceActivity.OpenProjectViewOnStart\": \"true\",\r\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\r\n    \"WebServerToolWindowFactoryState\": \"false\",\r\n    \"git-widget-placeholder\": \"main\",\r\n    \"last_opened_file_path\": \"D:/CMP/CMP7/NLP/Tashkila\",\r\n    \"settings.editor.selected.configurable\": \"com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable\"\r\n  }\r\n}]]></component>\r\n  <component name=\"RunManager\">\r\n    <configuration default=\"true\" type=\"PythonConfigurationType\" factoryName=\"Python\">\r\n      <module name=\"tashkila2\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration default=\"true\" type=\"Tox\" factoryName=\"Tox\">\r\n      <module name=\"tashkila2\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration default=\"true\" type=\"tests\" factoryName=\"Autodetect\">\r\n      <module name=\"tashkila2\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <option name=\"_new_additionalArguments\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_target\" value=\"&quot;&quot;\" />\r\n      <option name=\"_new_targetType\" value=\"&quot;PATH&quot;\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n    <configuration default=\"true\" type=\"tests\" factoryName=\"Doctests\">\r\n      <module name=\"tashkila2\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"\" />\r\n      <option name=\"CLASS_NAME\" value=\"\" />\r\n      <option name=\"METHOD_NAME\" value=\"\" />\r\n      <option name=\"FOLDER_NAME\" value=\"\" />\r\n      <option name=\"TEST_TYPE\" value=\"TEST_SCRIPT\" />\r\n      <option name=\"PATTERN\" value=\"\" />\r\n      <option name=\"USE_PATTERN\" value=\"false\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n  </component>\r\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\r\n  <component name=\"Vcs.Log.Tabs.Properties\">\r\n    <option name=\"TAB_STATES\">\r\n      <map>\r\n        <entry key=\"MAIN\">\r\n          <value>\r\n            <State />\r\n          </value>\r\n        </entry>\r\n      </map>\r\n    </option>\r\n  </component>\r\n  <component name=\"VcsManagerConfiguration\">\r\n    <MESSAGE value=\"add attention mechanism\" />\r\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"add attention mechanism\" />\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 1812371599fb00564644645c1b5dd2f839fba7af)
+++ b/.idea/workspace.xml	(date 1702948577235)
@@ -5,10 +5,10 @@
   </component>
   <component name="ChangeListManager">
     <list default="true" id="45d69a52-e93d-4b59-9786-d3bacb09f552" name="Changes" comment="add attention mechanism">
-      <change beforePath="$PROJECT_DIR$/.idea/inspectionProfiles/profiles_settings.xml" beforeDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/modules.xml" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/vcs.xml" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/attention.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/attention.ipynb" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/main.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/main.ipynb" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -42,30 +42,30 @@
     <option name="hideEmptyMiddlePackages" value="true" />
     <option name="showLibraryContents" value="true" />
   </component>
-  <component name="PropertiesComponent"><![CDATA[{
-  "keyToString": {
-    "RunOnceActivity.OpenProjectViewOnStart": "true",
-    "RunOnceActivity.ShowReadmeOnStart": "true",
-    "WebServerToolWindowFactoryState": "false",
-    "git-widget-placeholder": "main",
-    "last_opened_file_path": "D:/CMP/CMP7/NLP/Tashkila",
-    "settings.editor.selected.configurable": "com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable"
+  <component name="PropertiesComponent">{
+  &quot;keyToString&quot;: {
+    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,
+    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
+    &quot;WebServerToolWindowFactoryState&quot;: &quot;false&quot;,
+    &quot;git-widget-placeholder&quot;: &quot;main&quot;,
+    &quot;last_opened_file_path&quot;: &quot;D:/CMP/CMP7/NLP/Tashkila&quot;,
+    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;
   }
-}]]></component>
+}</component>
   <component name="RunManager">
-    <configuration default="true" type="PythonConfigurationType" factoryName="Python">
-      <module name="tashkila2" />
+    <configuration name="attention_test" type="PythonConfigurationType" factoryName="Python" nameIsGenerated="true">
+      <module name="Tashkila" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
       <envs>
         <env name="PYTHONUNBUFFERED" value="1" />
       </envs>
       <option name="SDK_HOME" value="" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
+      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
+      <option name="IS_MODULE_SDK" value="true" />
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
-      <option name="SCRIPT_NAME" value="" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/attention_test.py" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="false" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -74,49 +74,6 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration default="true" type="Tox" factoryName="Tox">
-      <module name="tashkila2" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <option name="SDK_HOME" value="" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <method v="2" />
-    </configuration>
-    <configuration default="true" type="tests" factoryName="Autodetect">
-      <module name="tashkila2" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <option name="SDK_HOME" value="" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <option name="_new_additionalArguments" value="&quot;&quot;" />
-      <option name="_new_target" value="&quot;&quot;" />
-      <option name="_new_targetType" value="&quot;PATH&quot;" />
-      <method v="2" />
-    </configuration>
-    <configuration default="true" type="tests" factoryName="Doctests">
-      <module name="tashkila2" />
-      <option name="INTERPRETER_OPTIONS" value="" />
-      <option name="PARENT_ENVS" value="true" />
-      <option name="SDK_HOME" value="" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
-      <option name="ADD_CONTENT_ROOTS" value="true" />
-      <option name="ADD_SOURCE_ROOTS" value="true" />
-      <option name="SCRIPT_NAME" value="" />
-      <option name="CLASS_NAME" value="" />
-      <option name="METHOD_NAME" value="" />
-      <option name="FOLDER_NAME" value="" />
-      <option name="TEST_TYPE" value="TEST_SCRIPT" />
-      <option name="PATTERN" value="" />
-      <option name="USE_PATTERN" value="false" />
-      <method v="2" />
-    </configuration>
   </component>
   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
   <component name="Vcs.Log.Tabs.Properties">
@@ -134,4 +91,15 @@
     <MESSAGE value="add attention mechanism" />
     <option name="LAST_COMMIT_MESSAGE" value="add attention mechanism" />
   </component>
+  <component name="XDebuggerManager">
+    <breakpoint-manager>
+      <breakpoints>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/attention_test.py</url>
+          <line>32</line>
+          <option name="timeStamp" value="1" />
+        </line-breakpoint>
+      </breakpoints>
+    </breakpoint-manager>
+  </component>
 </project>
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"Black\">\r\n    <option name=\"sdkName\" value=\"main\" />\r\n  </component>\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.10\" project-jdk-type=\"Python SDK\" />\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 1812371599fb00564644645c1b5dd2f839fba7af)
+++ b/.idea/misc.xml	(date 1702943268109)
@@ -4,4 +4,7 @@
     <option name="sdkName" value="main" />
   </component>
   <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.10" project-jdk-type="Python SDK" />
+  <component name="PyCharmDSProjectLayout">
+    <option name="id" value="JupyterRightHiddenStructureLayout" />
+  </component>
 </project>
\ No newline at end of file
