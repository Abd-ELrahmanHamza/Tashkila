{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all imports done\n"
     ]
    }
   ],
   "source": [
    "from letters_dataset import LettersDataset\n",
    "from seq2seq.byte_pair_encoding import Byte_Pair_Encoding\n",
    "from words_dataset import WordsDataset\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from train_collections import DS_ARABIC_LETTERS, DS_HARAKAT\n",
    "\n",
    "print(\"all imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=256, num_layers=1, dropout_probability=0.1):\n",
    "        super().__init__()\n",
    "        # TODO: replace with one hot encoding\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers, dropout=dropout_probability, batch_first=True)\n",
    "\n",
    "        # Dropout layer to prevent over fitting (regularization)\n",
    "        # it randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\n",
    "        self.dropout = nn.Dropout(dropout_probability)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs = [inputs len, batch size]\n",
    "        embeddings = self.dropout(self.embedding(inputs))\n",
    "\n",
    "        # embedded = [inputs len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.lstm_layer(embeddings)\n",
    "\n",
    "        # outputs = [inputs len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return outputs,(hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size+hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, context, h0, c0):\n",
    "        # print(\"from decoder forward\")\n",
    "        # print(x.shape)\n",
    "        embeddings = self.embedding(x)\n",
    "        # print(\"from decoder forward after embedding\")\n",
    "        # print(embeddings.shape)\n",
    "        lstm_input = torch.cat((embeddings, context), dim=2)\n",
    "        outs, (h1,c1) = self.lstm(lstm_input, (h0, c0))\n",
    "        # h is the output of the RNN\n",
    "        # hn is the hidden state of the last timestep\n",
    "        # cn is the cell state of the last timestep\n",
    "        scores = self.fc(outs)\n",
    "        return scores,(h1,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%Attention\n",
    "class AttentionSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs):\n",
    "        encoder_output, (encoder_hidden, encoder_cell) = self.encoder(encoder_inputs)\n",
    "        # print(\"hello\")\n",
    "        # add attention\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "        sequence_length = decoder_inputs.size(1)\n",
    "        batch_size = decoder_inputs.size(0)\n",
    "        # final output of the decoder\n",
    "        # batch size * sequence length * output size\n",
    "        final_output = torch.zeros(\n",
    "            batch_size, sequence_length, self.decoder.output_size, device=device)\n",
    "        for i in range(sequence_length):\n",
    "            attention_weights = self.calculate_attention_weights(encoder_output, decoder_hidden)\n",
    "            attention_vectors = attention_weights * encoder_output\n",
    "            context_vector = torch.sum(attention_vectors, dim=1, keepdim=True)\n",
    "            scores ,(decoder_hidden, decoder_cell) = self.decoder(decoder_inputs[:, i:i+1], context_vector, decoder_hidden, decoder_cell)\n",
    "            final_output[:, i:i+1, :] = scores\n",
    "        return final_output\n",
    "\n",
    "    def calculate_attention_weights(self, encoder_output, decoder_hidden):\n",
    "        # encoder output: [batch size, seq len, hidden size]\n",
    "        # decoder hidden: [1, batch size, hidden size]\n",
    "        # attention weights: [batch size, seq len, 1]\n",
    "        decoder_hidden_permuted = decoder_hidden.permute(1, 2, 0)\n",
    "        attention_weights = torch.bmm(encoder_output, decoder_hidden_permuted)\n",
    "        attention_weights = self.softmax(attention_weights)\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dim_vocab = len(DS_ARABIC_LETTERS)\n",
    "decoder_dim_out = len(DS_HARAKAT) + 2  # harakat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "n_epochs = 5\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = Byte_Pair_Encoding(450)\n",
    "bpe.train(\"./clean_out/merged.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 495\n",
      "adham\n"
     ]
    }
   ],
   "source": [
    "decodor_dataset = LettersDataset(\n",
    "    \"./clean_out/X.csv\", \"./clean_out/Y.csv\", device=device)\n",
    "encoder_dataset = WordsDataset(\n",
    "    \"./clean_out/X_words.txt\", device=device, tokenizer=bpe)\n",
    "print(\"adham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 450])\n",
      "torch.Size([64, 495])\n",
      "torch.Size([64, 495])\n"
     ]
    }
   ],
   "source": [
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, words_dataset, letters_dataset):\n",
    "        self.words_dataset = words_dataset\n",
    "        self.letters_dataset = letters_dataset\n",
    "\n",
    "        # Ensure both datasets are of the same size\n",
    "        assert len(words_dataset) == len(\n",
    "            letters_dataset), \"Datasets must be of the same size\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words_dataset[idx]\n",
    "        letters, letter_tashkeel = self.letters_dataset[idx]\n",
    "\n",
    "        # Combine or process the features as needed for your model\n",
    "        # This can vary depending on how your seq2seq model is set up\n",
    "\n",
    "        return word, letters, letter_tashkeel\n",
    "    \n",
    "merged_set = CombinedDataset(encoder_dataset, decodor_dataset)\n",
    "\n",
    "seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "sample = next(iter(seq2seq_loader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)\n",
    "print(sample[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionSeq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(30000, 128)\n",
      "    (lstm_layer): LSTM(128, 128, batch_first=True)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(60, 128)\n",
      "    (lstm): LSTM(256, 128, batch_first=True)\n",
      "    (fc): Linear(in_features=128, out_features=17, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=2)\n",
      ")\n",
      "Number of batches: 2590\n",
      "Epoch 0, batch 0: Loss = 3.0025\n"
     ]
    }
   ],
   "source": [
    "enc_model = Encoder(\n",
    "    encoder_dataset.bpe.tokenizer.get_vocab_size(), hidden_dim=128, num_layers=1, dropout_probability=0)\n",
    "\n",
    "dec_model = Decoder(decoder_dim_vocab, embedding_size=128,\n",
    "                    hidden_size=128, output_size=decoder_dim_out, device=device.type)\n",
    "\n",
    "\n",
    "model = AttentionSeq2Seq(encoder=enc_model, decoder=dec_model).to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_batches = len(seq2seq_loader)\n",
    "print(\"Number of batches:\", num_batches)\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for i, (X_encoder, X_decoder, Y_batch) in enumerate(seq2seq_loader):\n",
    "        y_pred = ''\n",
    "        y_pred = model(X_encoder, X_decoder)\n",
    "        y_pred = y_pred.transpose(1, 2)\n",
    "        # print(y_pred.shape)\n",
    "        # print(y_batch.shape)\n",
    "        loss = loss_fn(y_pred, Y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch %d, batch %d: Loss = %.4f\" % (epoch, i, loss))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\n",
    "            y_pred = model(X_encoder, X_decoder)\n",
    "            y_pred = y_pred.transpose(1, 2)\n",
    "\n",
    "            loss += loss_fn(y_pred, Y_batch)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LettersDataset(\n",
    "    './clean_out/X_val.csv', './clean_out/y_val.csv', device=device)\n",
    "val_words_dataset = WordsDataset(\n",
    "    './clean_out/X_words_val.txt', device=device, tokenizer=bpe)\n",
    "val_merged = CombinedDataset(val_words_dataset, val_dataset)\n",
    "seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\n",
    "        is_padding = (X_decoder == val_dataset.char_encoder.get_pad_token())\n",
    "        y_pred = model(X_encoder, X_decoder)\n",
    "        y_pred = y_pred.transpose(1, 2)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        # Count only non-padding characters\n",
    "        total += torch.sum(~is_padding).item()\n",
    "\n",
    "        # Count correct predictions\n",
    "        correct += torch.sum((predicted == Y_batch) & (~is_padding)).item()\n",
    "print(\"Accuracy: %.2f%%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
