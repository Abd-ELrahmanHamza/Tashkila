{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all imports done\n"
     ]
    }
   ],
   "source": [
    "from letters_dataset import LettersDataset\n",
    "from seq2seq.byte_pair_encoding import Byte_Pair_Encoding\n",
    "from words_dataset import WordsDataset\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from train_collections import DS_ARABIC_LETTERS, DS_HARAKAT\n",
    "\n",
    "print(\"all imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=256, num_layers=1, dropout_probability=0.1):\n",
    "        super().__init__()\n",
    "        # TODO: replace with one hot encoding\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers, dropout=dropout_probability, batch_first=True)\n",
    "\n",
    "        # Dropout layer to prevent over fitting (regularization)\n",
    "        # it randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\n",
    "        self.dropout = nn.Dropout(dropout_probability)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs = [inputs len, batch size]\n",
    "        embeddings = self.dropout(self.embedding(inputs))\n",
    "\n",
    "        # embedded = [inputs len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.lstm_layer(embeddings)\n",
    "\n",
    "        # outputs = [inputs len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return outputs,(hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size+hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, context, h0, c0):\n",
    "        # print(\"from decoder forward\")\n",
    "        # print(x.shape)\n",
    "        embeddings = self.embedding(x)\n",
    "        # print(\"from decoder forward after embedding\")\n",
    "        # print(embeddings.shape)\n",
    "        lstm_input = torch.cat((embeddings, context), dim=2)\n",
    "        outs, (h1,c1) = self.lstm(lstm_input, (h0, c0))\n",
    "        # h is the output of the RNN\n",
    "        # hn is the hidden state of the last timestep\n",
    "        # cn is the cell state of the last timestep\n",
    "        scores = self.fc(outs)\n",
    "        return scores,(h1,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%Attention\n",
    "class AttentionSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs):\n",
    "        encoder_output, (encoder_hidden, encoder_cell) = self.encoder(encoder_inputs)\n",
    "        # print(\"hello\")\n",
    "        # add attention\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "        sequence_length = decoder_inputs.size(1)\n",
    "        batch_size = decoder_inputs.size(0)\n",
    "        # final output of the decoder\n",
    "        # batch size * sequence length * output size\n",
    "        final_output = torch.zeros(\n",
    "            batch_size, sequence_length, self.decoder.output_size, device=device)\n",
    "        for i in range(sequence_length):\n",
    "            attention_weights = self.calculate_attention_weights(encoder_output, decoder_hidden)\n",
    "            attention_vectors = attention_weights * encoder_output\n",
    "            context_vector = torch.sum(attention_vectors, dim=1, keepdim=True)\n",
    "            scores ,(decoder_hidden, decoder_cell) = self.decoder(decoder_inputs[:, i:i+1], context_vector, decoder_hidden, decoder_cell)\n",
    "            final_output[:, i:i+1, :] = scores\n",
    "        return final_output\n",
    "\n",
    "    def calculate_attention_weights(self, encoder_output, decoder_hidden):\n",
    "        # encoder output: [batch size, seq len, hidden size]\n",
    "        # decoder hidden: [1, batch size, hidden size]\n",
    "        # attention weights: [batch size, seq len, 1]\n",
    "        decoder_hidden_permuted = decoder_hidden.permute(1, 2, 0)\n",
    "        attention_weights = torch.bmm(encoder_output, decoder_hidden_permuted)\n",
    "        attention_weights = self.softmax(attention_weights)\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dim_vocab = len(DS_ARABIC_LETTERS)\n",
    "decoder_dim_out = len(DS_HARAKAT) + 2  # harakat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "n_epochs = 5\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = Byte_Pair_Encoding(450)\n",
    "bpe.train(\"./clean_out/merged.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 495\n",
      "adham\n"
     ]
    }
   ],
   "source": [
    "decodor_dataset = LettersDataset(\n",
    "    \"./clean_out/X.csv\", \"./clean_out/Y.csv\", device=device)\n",
    "encoder_dataset = WordsDataset(\n",
    "    \"./clean_out/X_words.txt\", device=device, tokenizer=bpe)\n",
    "print(\"adham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 450])\n",
      "torch.Size([64, 495])\n",
      "torch.Size([64, 495])\n"
     ]
    }
   ],
   "source": [
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, words_dataset, letters_dataset):\n",
    "        self.words_dataset = words_dataset\n",
    "        self.letters_dataset = letters_dataset\n",
    "\n",
    "        # Ensure both datasets are of the same size\n",
    "        assert len(words_dataset) == len(\n",
    "            letters_dataset), \"Datasets must be of the same size\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words_dataset[idx]\n",
    "        letters, letter_tashkeel = self.letters_dataset[idx]\n",
    "\n",
    "        # Combine or process the features as needed for your model\n",
    "        # This can vary depending on how your seq2seq model is set up\n",
    "\n",
    "        return word, letters, letter_tashkeel\n",
    "    \n",
    "merged_set = CombinedDataset(encoder_dataset, decodor_dataset)\n",
    "\n",
    "seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "sample = next(iter(seq2seq_loader))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)\n",
    "print(sample[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionSeq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(30000, 128)\n",
      "    (lstm_layer): LSTM(128, 128, batch_first=True)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(60, 128)\n",
      "    (lstm): LSTM(256, 128, batch_first=True)\n",
      "    (fc): Linear(in_features=128, out_features=17, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=2)\n",
      ")\n",
      "Number of batches: 2590\n",
      "Epoch 0, batch 0: Loss = 2.5311\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26344\\1270333249.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m100\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\aatta\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    485\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    486\u001B[0m             )\n\u001B[1;32m--> 487\u001B[1;33m         torch.autograd.backward(\n\u001B[0m\u001B[0;32m    488\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    489\u001B[0m         )\n",
      "\u001B[1;32mc:\\Users\\aatta\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    198\u001B[0m     \u001B[1;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[1;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 200\u001B[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    201\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    202\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [16], line 26\u001B[0m\n\u001B[0;32m     24\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(y_pred, Y_batch)\n\u001B[0;32m     25\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 26\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mc:\\Users\\adham ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\adham ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "enc_model = Encoder(\n",
    "    encoder_dataset.bpe.tokenizer.get_vocab_size(), hidden_dim=128, num_layers=1, dropout_probability=0)\n",
    "\n",
    "dec_model = Decoder(decoder_dim_vocab, embedding_size=128,\n",
    "                    hidden_size=128, output_size=decoder_dim_out, device=device.type)\n",
    "\n",
    "\n",
    "model = AttentionSeq2Seq(encoder=enc_model, decoder=dec_model).to(device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_batches = len(seq2seq_loader)\n",
    "print(\"Number of batches:\", num_batches)\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for i, (X_encoder, X_decoder, Y_batch) in enumerate(seq2seq_loader):\n",
    "        y_pred = ''\n",
    "        y_pred = model(X_encoder, X_decoder)\n",
    "        y_pred = y_pred.transpose(1, 2)\n",
    "        # print(y_pred.shape)\n",
    "        # print(y_batch.shape)\n",
    "        loss = loss_fn(y_pred, Y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch %d, batch %d: Loss = %.4f\" % (epoch, i, loss))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\n",
    "            y_pred = model(X_encoder, X_decoder)\n",
    "            y_pred = y_pred.transpose(1, 2)\n",
    "\n",
    "            loss += loss_fn(y_pred, Y_batch)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LettersDataset(\n",
    "    './clean_out/X_val.csv', './clean_out/y_val.csv', device=device)\n",
    "val_words_dataset = WordsDataset(\n",
    "    './clean_out/X_words_val.txt', device=device, tokenizer=bpe)\n",
    "val_merged = CombinedDataset(val_words_dataset, val_dataset)\n",
    "seq2seq_loader = DataLoader(merged_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_encoder, X_decoder, Y_batch) in seq2seq_loader:\n",
    "        is_padding = (X_decoder == val_dataset.char_encoder.get_pad_token())\n",
    "        y_pred = model(X_encoder, X_decoder)\n",
    "        y_pred = y_pred.transpose(1, 2)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        # Count only non-padding characters\n",
    "        total += torch.sum(~is_padding).item()\n",
    "\n",
    "        # Count correct predictions\n",
    "        correct += torch.sum((predicted == Y_batch) & (~is_padding)).item()\n",
    "print(\"Accuracy: %.2f%%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
