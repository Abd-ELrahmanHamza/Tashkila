{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:15:19.650113400Z",
     "start_time": "2024-01-01T15:15:18.703184400Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'dataset'\n",
    "CLEAN_OUT_FOLDER = 'clean_out'\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:15:20.406563Z",
     "start_time": "2024-01-01T15:15:19.646330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (55000,)\n",
      "first 5 examples: \n",
      "0    قَوْلُهُ : ( أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَ...\n",
      "1    ابْنُ عَرَفَةَ : قَوْلُهُ : بِلَفْظٍ يَقْتَضِي...\n",
      "2    ( قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ ) أَ...\n",
      "3                       وَحَيَوَانٌ غَيْرُ مَوْجُودٍ .\n",
      "4    فَائِدَةٌ : قَالَ بَعْضُهُمْ : يُؤْخَذُ مِنْ ش...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read dataset train \n",
    "def read_dataset(file_name='train.txt', verbose=False):\n",
    "    \"\"\"\n",
    "    takes a file name and returns a pandas dataframe of the dataset \n",
    "    the returnes is a pandas series of the dataset \n",
    "    \"\"\"\n",
    "\n",
    "    dataset = os.path.join(DATASET_FOLDER, file_name)\n",
    "    # read dataset as a text file and each line as a training example\n",
    "    dataset = pd.read_csv(dataset, sep='\\t', header=None).squeeze('columns')\n",
    "\n",
    "    if verbose:\n",
    "        print('dataset shape: ', dataset.shape)\n",
    "        print('first 5 examples: ')\n",
    "        print(dataset[:5])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "read_dataset(verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:15:20.448396300Z",
     "start_time": "2024-01-01T15:15:20.408606300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:15:20.457915100Z",
     "start_time": "2024-01-01T15:15:20.423578400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "ت 1578\n",
      "َ 1614\n",
      "غ 1594\n",
      "ْ 1618\n",
      "ت 1578\n",
      "َ 1614\n",
      "ر 1585\n",
      "ّ 1617\n",
      "َ 1614\n",
      "--------------------\n",
      "يّيلعبُُُ\n"
     ]
    }
   ],
   "source": [
    "text = 'تَغْتَرَّ'\n",
    "print(len(text))\n",
    "\n",
    "# shadda and other diacritics are single characters\n",
    "for i in range(len(text)):\n",
    "    print(text[i], ord(text[i]))\n",
    "\n",
    "print('--------------------')\n",
    "\n",
    "print(\"يّيلعبُُُ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:15:32.303234100Z",
     "start_time": "2024-01-01T15:15:20.436763200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2', '«', '؟', 'ُ', 'ٌ', '~', '(', '3', '-', '»', 'ْ', '9', 'ٍ', '؛', ':', '1', '6', '!', '4', ';', '0', '[', '7', '*', '–', '{', '5', '\\u200f', '`', 'ً', ']', '8', '}', '.', ',', ')', '\"', 'َ', ' ', '/', 'ّ', '،', \"'\", 'ِ'}\n"
     ]
    }
   ],
   "source": [
    "# geet all the tashkeel in the text \n",
    "from constants import ARABIC_LETTERS\n",
    "\n",
    "All_NON_Letters = set()\n",
    "for text in read_dataset():\n",
    "    for c in text:\n",
    "        if c not in ARABIC_LETTERS:\n",
    "            All_NON_Letters.add(c)\n",
    "\n",
    "print(All_NON_Letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:15:33.034473500Z",
     "start_time": "2024-01-01T15:15:32.310286700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ز؟:.+_@#$.زتَغْتَرَّ//،،)()( جداى آيئءؤرلاىةوزظلآج)\n",
      "قَوْلُهُ : ( أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ ) قَالَ الزَّرْكَشِيُّ( 14 / 123 )\n",
      "قَوْلُهُ : ( أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ ) قَالَ الزَّرْكَشِيُّ( / )\n",
      "---------------------\n",
      "2 « ؟ ُ ٌ ~ ( 3 - » ْ 9 ٍ ؛ : 1 6 ! 4 ; 0 [ 7 * – { 5 ‏ ` ً ] 8 } . , ) \" َ   / ّ ، ' ِ\n",
      "« ؟ ُ ٌ ~ ( - » ْ ٍ ؛ : ! ; [ * – { ‏ ` ً ] } . , ) \" َ / ّ ، ' ِ\n"
     ]
    }
   ],
   "source": [
    "from regex import P\n",
    "from constants.arabic import HARAKAT\n",
    "from constants import PUNCTUATIONS\n",
    "from constants.arabic import ARABIC_NUMBERS\n",
    "\n",
    "import re\n",
    "import re\n",
    "from constants.arabic import ARABIC_NUMBERS\n",
    "from constants import PUNCTUATIONS\n",
    "\n",
    "# Compile regular expressions\n",
    "number_regex = re.compile(r'[0-9]')\n",
    "arabic_number_regex = re.compile(r'[' + \"\".join(ARABIC_NUMBERS) + ']')\n",
    "punctuation_regex = re.compile(r'[' + \"\".join(PUNCTUATIONS) + ']')\n",
    "spaces_regex = re.compile(r'\\s+')\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Delete all numbers and punctuation\n",
    "    # Remove numbers\n",
    "    text = number_regex.sub('', text)\n",
    "    text = arabic_number_regex.sub('', text)\n",
    "    # Remove punctuation marks\n",
    "    # text = punctuation_regex.sub('', text)\n",
    "    # Compress all spaces\n",
    "    text = spaces_regex.sub(' ', text)\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "text = '   0110ز؟:.+_@#$.زتَغْتَرَّ2//،،312)()( جداى آيئءؤرلاىةوزظلآج)'\n",
    "print(clean_text(text))\n",
    "\n",
    "dataset = read_dataset()\n",
    "\n",
    "for t in dataset[:5]:\n",
    "    print(t)\n",
    "    print(clean_text(t))\n",
    "    print('---------------------')\n",
    "    break\n",
    "\n",
    "non_letters = ' '.join(list(All_NON_Letters))\n",
    "print(non_letters)\n",
    "cleaned = clean_text(non_letters)\n",
    "print(cleaned)  # only tashkeel  and spaces left -> for now \n",
    "# print(PUNCTUATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:25.033927700Z",
     "start_time": "2024-01-01T15:15:33.050589100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55000/55000 [00:13<00:00, 4086.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create X and Y to the model\n",
    "# X is the input and Y is the output (the target)\n",
    "# X is a list of all the characters in the dataset\n",
    "# Y is a list of all Diacritics in the dataset (the target)\n",
    "# if the character has no diacritic, the diacritic is set to be $ (empty diacritic)\n",
    "from constants.arabic import HARAKAT, SHADDA, ARABIC_LETTERS\n",
    "from train_collections import harakat2id\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "train = read_dataset()\n",
    "\n",
    "\n",
    "def xy_dataset(dataset, is_test=False):\n",
    "    \"\"\"\n",
    "    dataset: pandas series of the dataset (each example is a string)\n",
    "    return: X, Y as lists\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    X_words = []\n",
    "    Y = []\n",
    "\n",
    "    for line in tqdm(dataset):\n",
    "        cleaned_line = clean_text(line)\n",
    "        delimiters = [\",\", \"|\", \";\", \"؛\", \".\", \":\", \"(\", \")\", \"<\", \">\", \"[\", \"]\", \"{\", \"}\"]\n",
    "        splited_lines = re.split('[' + ''.join(map(re.escape, delimiters)) + ']', cleaned_line)\n",
    "        for cleaned_line in splited_lines:\n",
    "\n",
    "            if len(cleaned_line) < 1 or (len(cleaned_line) < 4 and not is_test):\n",
    "                continue\n",
    "\n",
    "            line_x = []\n",
    "            line_y = []\n",
    "            i = 0\n",
    "            while i < len(cleaned_line):\n",
    "                c = cleaned_line[i]\n",
    "                line_x.append(c)\n",
    "\n",
    "                # if this is the last character in the line or the next character is not a tashkeel \n",
    "                # then the tashkeel is empty\n",
    "                if i == len(cleaned_line) - 1 or cleaned_line[i + 1] not in HARAKAT:\n",
    "                    line_y.append('$')\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                i += 1\n",
    "                tashkeel = cleaned_line[i]\n",
    "                # if this is a shadda, we need to add the next character to the tashkeel\n",
    "                # as shadda  ّ dont come alone\n",
    "                if tashkeel == SHADDA and (i < len(cleaned_line) - 1 and cleaned_line[i + 1] in HARAKAT):\n",
    "                    i += 1\n",
    "                    tashkeel += cleaned_line[i]\n",
    "\n",
    "                line_y.append(tashkeel)\n",
    "\n",
    "                i += 1\n",
    "            # add words to X_words\n",
    "            X_words.append(''.join(line_x).split())\n",
    "            X.append(line_x)\n",
    "            Y.append(line_y)\n",
    "\n",
    "    return X_words, X, Y\n",
    "\n",
    "\n",
    "train_set = read_dataset()\n",
    "X_words, X, Y = xy_dataset(train_set)\n",
    "\n",
    "# make sure they are the same length (each x has a y of the same length)\n",
    "for x, y in zip(X, Y):\n",
    "    assert len(x) == len(y)\n",
    "\n",
    "\n",
    "def convert_to_gold_standard_format(X, Y, name='train'):\n",
    "    \"\"\"\n",
    "    X is a list of lists of characters\n",
    "    Y is a list of lists of diacritics\n",
    "    return is a csv file in the gold standard format \n",
    "    ID,label\n",
    "    \"\"\"\n",
    "    pfile = pd.DataFrame(columns=['ID', 'letter', 'label'])\n",
    "    pairs = []\n",
    "    for sent, tags in zip(X, Y):\n",
    "        for c, t in zip(sent, tags):\n",
    "            if c in ARABIC_LETTERS:\n",
    "                if t == '$':\n",
    "                    t = ''\n",
    "                pairs.append([c, harakat2id[t]])\n",
    "\n",
    "    pfile['ID'] = [i for i in range(len(pairs))]\n",
    "    pfile['letter'] = [pair[0] for pair in pairs]\n",
    "    pfile['label'] = [pair[1] for pair in pairs]\n",
    "    pfile.to_csv(f\"./clean_out/{name}_gold\" + '.csv', index=False)\n",
    "\n",
    "\n",
    "# save outs into 3 files in CLEAN_OUT_FOLDER   \n",
    "\n",
    "def save_dataset(X, Y, X_words, x_file='X.csv', y_file='Y.csv', x_words_file='X_words.txt'):\n",
    "    \"\"\"\n",
    "    save X, Y, X_words into 3 files in CLEAN_OUT_FOLDER\n",
    "    \"\"\"\n",
    "    # make sure the folder exists\n",
    "    if not os.path.exists(CLEAN_OUT_FOLDER):\n",
    "        os.makedirs(CLEAN_OUT_FOLDER)\n",
    "    # save X\n",
    "    with open(os.path.join(CLEAN_OUT_FOLDER, x_file), 'w', encoding=\"utf8\") as f:\n",
    "        for line in X:\n",
    "            f.write('s'.join(line) + '\\n')\n",
    "\n",
    "    # save Y\n",
    "    with open(os.path.join(CLEAN_OUT_FOLDER, y_file), 'w', encoding=\"utf8\") as f:\n",
    "        for line in Y:\n",
    "            f.write('s'.join(line) + '\\n')\n",
    "\n",
    "    # save X_words\n",
    "    with open(os.path.join(CLEAN_OUT_FOLDER, x_words_file), 'w', encoding=\"utf8\") as f:\n",
    "        for line in X_words:\n",
    "            f.write(' '.join(line) + '\\n')\n",
    "\n",
    "\n",
    "save_dataset(X, Y, X_words)\n",
    "\n",
    "convert_to_gold_standard_format(X, Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:25.049713100Z",
     "start_time": "2024-01-01T15:16:25.034893500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:25.111047700Z",
     "start_time": "2024-01-01T15:16:25.054334200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "194\n",
      "  $\n",
      "ب َ\n",
      "ي َّ\n",
      "ن َ\n",
      "  $\n",
      "ف ِ\n",
      "ي $\n",
      "  $\n",
      "ش َ\n",
      "ر ْ\n",
      "ح ِ\n",
      "  $\n",
      "ا $\n",
      "ل $\n",
      "ر َّ\n",
      "و ْ\n",
      "ض ِ\n",
      "  $\n",
      "أ َ\n",
      "ن َّ\n",
      "  $\n",
      "إ $\n",
      "ج ْ\n",
      "ز َ\n",
      "ا $\n",
      "ء َ\n",
      "  $\n",
      "ذ َ\n",
      "ب ْ\n",
      "ح ِ\n",
      "ه ِ\n",
      "  $\n",
      "ف ِ\n",
      "ي $\n",
      "  $\n",
      "س َ\n",
      "ن َ\n",
      "ة ِ\n",
      "  $\n",
      "ا $\n",
      "ل ْ\n",
      "ق َ\n",
      "ض َ\n",
      "ا $\n",
      "ء ِ\n",
      "  $\n",
      "ب َ\n",
      "ع ْ\n",
      "د َ\n",
      "  $\n",
      "د ُ\n",
      "خ ُ\n",
      "و $\n",
      "ل ِ\n",
      "  $\n",
      "و َ\n",
      "ق ْ\n",
      "ت ِ\n",
      "ه ِ\n",
      "  $\n",
      "و َ\n",
      "ق َ\n",
      "ب ْ\n",
      "ل َ\n",
      "  $\n",
      "ا $\n",
      "ل ْ\n",
      "إ ِ\n",
      "ح ْ\n",
      "ر َ\n",
      "ا $\n",
      "م ِ\n",
      "  $\n",
      "ب ِ\n",
      "ه ِ\n",
      "  $\n",
      "ه ُ\n",
      "و َ\n",
      "  $\n",
      "م َ\n",
      "ا $\n",
      "  $\n",
      "د َ\n",
      "ل َّ\n",
      "  $\n",
      "ع َ\n",
      "ل َ\n",
      "ي ْ\n",
      "ه ِ\n",
      "  $\n",
      "ك َ\n",
      "ل َ\n",
      "ا $\n",
      "م ُ\n",
      "  $\n",
      "أ َ\n",
      "ص ْ\n",
      "ل ِ\n",
      "ه ِ\n",
      "  $\n",
      "ت َ\n",
      "ب َ\n",
      "ع ً\n",
      "ا $\n",
      "  $\n",
      "ل ِ\n",
      "ل ْ\n",
      "ع ِ\n",
      "ر َ\n",
      "ا $\n",
      "ق ِ\n",
      "ي ِّ\n",
      "ي $\n",
      "ن َ\n",
      "  $\n",
      "، $\n",
      "  $\n",
      "و َ\n",
      "أ َ\n",
      "ن َّ\n",
      "  $\n",
      "م َ\n",
      "ا $\n",
      "  $\n",
      "و َ\n",
      "ق َ\n",
      "ع َ\n",
      "  $\n",
      "ف ِ\n",
      "ي $\n",
      "  $\n",
      "ا $\n",
      "ل $\n",
      "ر َّ\n",
      "و ْ\n",
      "ض ِ\n",
      "  $\n",
      "م ِ\n",
      "م َّ\n",
      "ا $\n",
      "  $\n",
      "ي ُ\n",
      "خ َ\n",
      "ا $\n",
      "ل ِ\n",
      "ف ُ\n",
      "  $\n",
      "ذ َ\n",
      "ل ِ\n",
      "ك َ\n",
      "  $\n",
      "م ِ\n",
      "ن ْ\n",
      "  $\n",
      "ت َ\n",
      "ص َ\n",
      "ر ُّ\n",
      "ف ِ\n",
      "ه ِ\n",
      "  $\n",
      "ق َ\n",
      "ا $\n",
      "ل َ\n",
      "  $\n",
      "ه َ\n",
      "ك َ\n",
      "ذ َ\n",
      "ا $\n",
      "  $\n",
      "أ َ\n",
      "ف ْ\n",
      "ه َ\n",
      "م ُ\n",
      "  $\n",
      "و َ\n",
      "ل َ\n",
      "ا $\n",
      "  $\n",
      "ت َ\n",
      "غ ْ\n",
      "ت َ\n",
      "ر َّ\n",
      "  $\n",
      "ب ِ\n",
      "م َ\n",
      "ا $\n",
      "  $\n",
      "ي ُ\n",
      "خ َ\n",
      "ا $\n",
      "ل ِ\n",
      "ف ُ\n",
      "ه ُ\n",
      "  $\n"
     ]
    }
   ],
   "source": [
    "# print them side by side \n",
    "print(len(X[544]))\n",
    "print(len(Y[544]))\n",
    "for x, y in zip(X[544], Y[544]):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (2494,)\n",
      "first 5 examples: \n",
      "0    لَيْسَ لِلْوَكِيلِ بِالْقَبْضِ أَنْ يُبَرِّأَ ...\n",
      "1    ( قَوْلُهُ وَيَقَعُ فِي بَعْضِ النُّسَخِ بِمَن...\n",
      "2    وَمَا ثَبَتَ بِظَنِّيٍّ سَاقِطٍ مِنْ قِسْمِ ال...\n",
      "3    26093 - حَدَّثَنَا عُثْمَانُ بْنُ عُمَرَ قَالَ...\n",
      "4    لِأَنَّ الْحَمْلَ فِيهَا لَا يُفِيدُ أُمَيَّةَ...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:00<00:00, 4108.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# val dataset too \n",
    "# val_dataset_f = os.path.join(DATASET_FOLDER, 'val.txt')\n",
    "# read dataset as a text file and each line as a training example\n",
    "val_dataset = read_dataset('test_with_diacritics.txt', verbose=True)\n",
    "X_words, X, Y = xy_dataset(val_dataset)\n",
    "convert_to_gold_standard_format(X, Y, name='test_with_diacritics')\n",
    "save_dataset(X, Y, X_words, x_file='X_test_with_diacritics.csv', y_file='Y_test_with_diacritics.csv', x_words_file='X_words_test_with_diacritics.txt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:27.671393700Z",
     "start_time": "2024-01-01T15:16:25.070140700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:29.440831Z",
     "start_time": "2024-01-01T15:16:27.676901400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (2500,)\n",
      "first 5 examples: \n",
      "0       ( 27 ) قَوْلُهُ : وَلَا تُكْرَهُ ضِيَافَتُهُ .\n",
      "1    ( الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ ...\n",
      "2    ( قَوْلُهُ : وَهُوَ ) أَيْ : الْبَيْعُ بِالْمَ...\n",
      "3    وَالْعَفْوُ قَبْلَ الْإِمَامِ ، أَوْ بَعْدَهُ ...\n",
      "4    ( قَوْلُهُ : وَرِبْحُهُ ) أَيْ الْقِرَاضِ وَقَ...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:00<00:00, 4721.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# val dataset too \n",
    "# val_dataset_f = os.path.join(DATASET_FOLDER, 'val.txt')\n",
    "# read dataset as a text file and each line as a training example\n",
    "val_dataset = read_dataset('val.txt', verbose=True)\n",
    "X_words, X, Y = xy_dataset(val_dataset)\n",
    "convert_to_gold_standard_format(X, Y, name='val')\n",
    "save_dataset(X, Y, X_words, x_file='X_val.csv', y_file='Y_val.csv', x_words_file='X_words_val.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:31.242888800Z",
     "start_time": "2024-01-01T15:16:29.439728200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (2500,)\n",
      "first 5 examples: \n",
      "0    ( قَوْلُهُ : وَلَوْ ادَّعَى وَلَدَ أَمَةٍ مُشْ...\n",
      "1    قَوْلُهُ : ( وَبَحَثَ الرَّافِعِيُّ صِحَّتَهَا...\n",
      "2    وَالْهَاوَنُ مِثَالٌ ، فَمِثْلُهُ كُلُّ مَا يَ...\n",
      "3    وَيَرُدُّ عَلَيْهِ أَنَّ فَاقِدَ الطَّهُورَيْن...\n",
      "4    كُهَيْلٍ قَالَ سَمِعْتُ أَبِي يُحَدِّثُ عَنْ ح...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:00<00:00, 4667.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# test dataset too\n",
    "test_dataset = read_dataset('test.txt', verbose=True)\n",
    "X_words, X, Y = xy_dataset(test_dataset, is_test=True)\n",
    "convert_to_gold_standard_format(X, Y, name='test')\n",
    "save_dataset(X, Y, X_words, x_file='X_test.csv', y_file='Y_test.csv', x_words_file='X_words_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:32.941100Z",
     "start_time": "2024-01-01T15:16:31.242888800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (2500,)\n",
      "first 5 examples: \n",
      "0    ليس للوكيل بالقبض أن يبرأ المدين أو يهب الدين ...\n",
      "1    ( قوله ويقع في بعض النسخ بمنفعة ومعين ) أي : أ...\n",
      "2                   وما ثبت بظني ساقط من قسم المعلوم .\n",
      "3    26093 - حدثنا عثمان بن عمر قال حدثنا مالك عن ا...\n",
      "4    لأن الحمل فيها لا يفيد أمية الولد ( فإن كانت ا...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:00<00:00, 5601.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# test dataset too\n",
    "test_dataset = read_dataset('./test_no_diacritics.txt', verbose=True)\n",
    "X_words, X, Y = xy_dataset(test_dataset, is_test=True)\n",
    "convert_to_gold_standard_format(X, Y, name='test_no_diacritics')\n",
    "save_dataset(X, Y, X_words, x_file='X_test_no_diacritics.csv', y_file='Y_test_no_diacritics.csv', x_words_file='test_no_diacritics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:39.519948900Z",
     "start_time": "2024-01-01T15:16:32.943285200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:  (2500,)\n",
      "first 5 examples: \n",
      "0    ( قوله : ولو ادعى ولد أمة مشتركة ثبت نسبه ، وه...\n",
      "1    قوله : ( وبحث الرافعي صحتها ) وإن قصد تمليك ال...\n",
      "2    والهاون مثال ، فمثله كل ما يتعذر كسره على رأسها .\n",
      "3    ويرد عليه أن فاقد الطهورين ونحوه ليس له صلاة إ...\n",
      "4    كهيل قال سمعت أبي يحدث عن حبة العرني قال رأيت ...\n",
      "Name: 0, dtype: object\n",
      "dataset shape:  (2500,)\n",
      "first 5 examples: \n",
      "0    ( قَوْلُهُ : وَلَوْ ادَّعَى وَلَدَ أَمَةٍ مُشْ...\n",
      "1    قَوْلُهُ : ( وَبَحَثَ الرَّافِعِيُّ صِحَّتَهَا...\n",
      "2    وَالْهَاوَنُ مِثَالٌ ، فَمِثْلُهُ كُلُّ مَا يَ...\n",
      "3    وَيَرُدُّ عَلَيْهِ أَنَّ فَاقِدَ الطَّهُورَيْن...\n",
      "4    كُهَيْلٍ قَالَ سَمِعْتُ أَبِي يُحَدِّثُ عَنْ ح...\n",
      "Name: 0, dtype: object\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:00<00:00, 5112.93it/s]\n",
      "100%|██████████| 2500/2500 [00:00<00:00, 3935.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11262\n",
      "11262\n",
      "[' ', 'أ', 'ي', ' ', 'ا', 'ل', 'ن', 'ا', 'ص', 'ي', 'ة', ' ', 'و', 'ذ', 'ك', 'ر', 'ه', ' ', 'م', 'ر', 'ا', 'ع', 'ا', 'ة', ' ', 'ل', 'ل', 'خ', 'ب', 'ر', ' ', 'و', 'ه', 'و', ' ', 'ق', 'و', 'ل', 'ه', ' ', 'م', 'ق', 'د', 'م', ' ', '،', ' ', 'و', 'ي', 'ج', 'و', 'ز', ' ', 'ت', 'أ', 'ن', 'ي', 'ث', 'ه', ' ', 'أ', 'ي', 'ض', 'ا', ' ', '،', ' ', 'و', 'ا', 'ل', 'ت', 'ذ', 'ك', 'ي', 'ر', ' ', 'ه', 'ن', 'ا', ' ', 'أ', 'و', 'ل', 'ى', ' ']\n",
      "[' ', 'أ', 'ي', ' ', 'ا', 'ل', 'ن', 'ا', 'ص', 'ي', 'ة', ' ', 'و', 'ذ', 'ك', 'ر', 'ه', ' ', 'م', 'ر', 'ا', 'ع', 'ا', 'ة', ' ', 'ل', 'ل', 'خ', 'ب', 'ر', ' ', 'و', 'ه', 'و', ' ', 'ق', 'و', 'ل', 'ه', ' ', 'م', 'ق', 'د', 'م', ' ', '،', ' ', 'و', 'ي', 'ج', 'و', 'ز', ' ', 'ت', 'أ', 'ن', 'ي', 'ث', 'ه', ' ', 'أ', 'ي', 'ض', 'ا', ' ', '،', ' ', 'و', 'ا', 'ل', 'ت', 'ذ', 'ك', 'ي', 'ر', ' ', 'ه', 'ن', 'ا', ' ', 'أ', 'و', 'ل', 'ى', ' ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_dataset = read_dataset('test_no_harakat.txt', verbose=True)\n",
    "test_no_dataset = read_dataset('test.txt', verbose=True)\n",
    "print(len(test_dataset))\n",
    "\n",
    "print(len(test_no_dataset))\n",
    "X_words, X, Y = xy_dataset(test_dataset, is_test=True)\n",
    "X_words, XX, YY = xy_dataset(test_no_dataset, is_test=True)\n",
    "print(XX[22] == X[22])\n",
    "print(len(X))\n",
    "print(len(XX))\n",
    "print(XX[22])\n",
    "print(X[22])\n",
    "convert_to_gold_standard_format(X, Y, name='test_no_harakat')\n",
    "convert_to_gold_standard_format(XX, YY, name='test')\n",
    "\n",
    "save_dataset(X, Y, X_words, x_file='X_test_no_harakat.csv', y_file='Y_test_no_harakat.csv', x_words_file='X_words_test_no_harkat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:39.897860500Z",
     "start_time": "2024-01-01T15:16:39.514955200Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_all_text(file_names: list[str]):\n",
    "    \"\"\"\n",
    "    takes a list of file names and merge them into one text file\n",
    "    \"\"\"\n",
    "    with open(f'{CLEAN_OUT_FOLDER}/merged.txt', 'w', encoding=\"utf8\") as outfile:\n",
    "        for fname in file_names:\n",
    "            with open(fname, encoding=\"utf8\") as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "\n",
    "\n",
    "cln_train = os.path.join(CLEAN_OUT_FOLDER, 'X_words.txt')\n",
    "cln_val = os.path.join(CLEAN_OUT_FOLDER, 'X_words_val.txt')\n",
    "merge_all_text([cln_train, cln_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:53.384617200Z",
     "start_time": "2024-01-01T15:16:39.903341Z"
    }
   },
   "outputs": [],
   "source": [
    "# from py import test\n",
    "\n",
    "train = read_dataset()\n",
    "val = read_dataset('val.txt')\n",
    "test = read_dataset('test.txt')\n",
    "with open(f'{CLEAN_OUT_FOLDER}/merged_unsplited.txt', 'w', encoding=\"utf8\") as infile:\n",
    "    trainfile = open(f'{CLEAN_OUT_FOLDER}/train_unsplited.txt', 'w', encoding=\"utf8\")\n",
    "    valfile = open(f'{CLEAN_OUT_FOLDER}/val_unsplited.txt', 'w', encoding=\"utf8\")\n",
    "    testfile = open(f'{CLEAN_OUT_FOLDER}/test_unsplited.txt', 'w', encoding=\"utf8\")\n",
    "    # keep only arabic letters and spaces\n",
    "    for t in train:\n",
    "        ll = ''.join([c for c in t if c in ARABIC_LETTERS or c == ' '])\n",
    "        ll = re.sub(r'\\s+', ' ', ll) + '\\n'\n",
    "        trainfile.write(ll)\n",
    "        infile.write(ll)\n",
    "\n",
    "    for t in val:\n",
    "        ll = ''.join([c for c in t if c in ARABIC_LETTERS or c == ' '])\n",
    "        ll = re.sub(r'\\s+', ' ', ll) + '\\n'\n",
    "        valfile.write(ll)\n",
    "        infile.write(ll)\n",
    "\n",
    "    for t in test:\n",
    "        ll = ''.join([c for c in t if c in ARABIC_LETTERS or c == ' '])\n",
    "        ll = re.sub(r'\\s+', ' ', ll) + '\\n'\n",
    "        testfile.write(ll)\n",
    "        infile.write(ll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:53.527322800Z",
     "start_time": "2024-01-01T15:16:53.389683600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14}\n"
     ]
    }
   ],
   "source": [
    "print(harakat2id)\n",
    "\n",
    "with open(f'{DATASET_FOLDER}/test.txt', 'r', encoding=\"utf8\") as infile:\n",
    "    # remove all the harakat from the test file\n",
    "    with open(f'{CLEAN_OUT_FOLDER}/test_no_harakat.txt', 'w', encoding=\"utf8\") as outfile:\n",
    "        for line in infile:\n",
    "            line = ''.join([c for c in line if c not in harakat2id])\n",
    "            outfile.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:53.583676500Z",
     "start_time": "2024-01-01T15:16:53.527322800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:16:54.611421Z",
     "start_time": "2024-01-01T15:16:53.542953200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'مدرس'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.arlstem import ARLSTem\n",
    "\n",
    "stemmer = ARLSTem()\n",
    "stemmer.stem('المدرسة')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
