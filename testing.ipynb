{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from letters_dataset import LettersDataset\n",
    "from accio import Accio\n",
    "from torch.utils import data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "device = torch.device(\"cpu\")\n",
    "model = Accio(input_size=41,output_size=15,device=device)\n",
    "model.load_state_dict(torch.load('./models/accio_epoch_19.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 190\n"
     ]
    }
   ],
   "source": [
    "val_dataset = LettersDataset('clean_out/X_demo.csv', 'clean_out/Y_demo.csv',val_mode=True, device=device)  \n",
    "val_loader = data.DataLoader(val_dataset,  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "صُعِدْ أَدْهَمَ وَحَمْزَةَ الشَّجَرَةِ حَتَّى يَقْطَعَا الطَّرِيقَ عَلَى الْأَشْرَارِ وَيُنْقِّذَا الْأَمِيرَةَ وَلَكِنْ لَمْ يُنَجِّحَا فِي ذَلِكَ وَلَكِنَّهُمَا تَمَكَّنَا مِنْ الْهَرَبِ وَالْعَوْدَةِ إِلَى الْقَرْيَةِ وَتَقَرَّرُ الْأَمِيرَةُ الزَّوَاجُ مِنْ أَدْهِمَ وَتَعَيُّشًا سَعِيدَيْنِ مَعًا، وَلَكِنْ قَالَ حَمْزَةُ<unk>لَا يُوجَدُ أَشْرَارٌ عَلَى الشَّجَرَةِ\n"
     ]
    }
   ],
   "source": [
    "# evaluaate accuracy on validation set\n",
    "model.eval()\n",
    "letter_haraka = []\n",
    "\n",
    "line_constructed = ''\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_batch,y_batch) in val_loader:\n",
    "        # y_pred = model(X_batch)['diacritics']\n",
    "        y_pred = model(X_batch)\n",
    "        # we transpose because the loss function expects the second dimension to be the classes\n",
    "        # y_pred is now (batch_size, n_classes, seq_len)\n",
    "        y_pred = y_pred.transpose(1, 2)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        # Count only non-padding characters\n",
    "        for x,y in zip(X_batch,predicted):\n",
    "            for xx,yy in zip(x,y):\n",
    "                # we reached the end of the sentence\n",
    "                # print(xx.item())\n",
    "                # print(val_dataset.char_encoder.get_pad_id())\n",
    "                # print(val_dataset.char_encoder.get_id_by_token(UNK_TOKEN))\n",
    "                if xx.item() == val_dataset.char_encoder.get_pad_id():\n",
    "                    break\n",
    "                \n",
    "                line_constructed += val_dataset.char_encoder.get_token_by_id(xx.item())\n",
    "                ll = val_dataset.char_encoder.is_arabic_letter(xx.item())\n",
    "                \n",
    "                if ll:\n",
    "                    letter_haraka.append([ll,yy.item()])\n",
    "                    line_constructed += val_dataset.harakat_encoder.get_token_by_id(yy.item())\n",
    "\n",
    "\n",
    "# for l in letter_haraka:\n",
    "#     line_constructed += l[0]\n",
    "#     line_constructed += val_dataset.harakat_encoder.get_token_by_id(l[1])\n",
    "print(line_constructed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
