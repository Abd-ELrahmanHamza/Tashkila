{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T21:45:14.157785500Z",
     "start_time": "2023-12-09T21:45:14.122263500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'write_connection_file' could not be imported from 'c:\\Users\\aatta\\anaconda3\\lib\\site-packages\\jupyter_client\\__init__.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c9d7979107b69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d06c7f266dbef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T21:45:14.191791500Z",
     "start_time": "2023-12-09T21:45:14.133792500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'write_connection_file' could not be imported from 'c:\\Users\\aatta\\anaconda3\\lib\\site-packages\\jupyter_client\\__init__.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8879b5a840b7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a06d932a5f623e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T21:45:14.192790Z",
     "start_time": "2023-12-09T21:45:14.152801Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, dropout_probability):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_layer = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout_probability)\n",
    "\n",
    "        # Dropout layer to prevent over fitting (regularization)\n",
    "        # it randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\n",
    "        self.dropout = nn.Dropout(dropout_probability)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        # inputs = [inputs len, batch size]\n",
    "        dropout_embeddings = self.dropout(embeddings)\n",
    "\n",
    "        # embedded = [inputs len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.lstm_layer(dropout_embeddings)\n",
    "\n",
    "        # outputs = [inputs len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cd3fa6b68bdc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a16e4d343a2b13",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125423347cfa284b",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from byte_pair_encoding import Byte_Pair_Encoding\n",
    "from letters_dataset import read_data, find_width_99_percentile\n",
    "\n",
    "\n",
    "\n",
    "input, expected_output = read_data(\"./clean_out/X.csv\", \"./clean_out/Y.csv\", True)\n",
    "print(input[0])\n",
    "# Find the max sentence length\n",
    "max_sentence_length = find_width_99_percentile(input)\n",
    "\n",
    "bpe = Byte_Pair_Encoding(max_sentence_length)\n",
    "bpe.train(\"./clean_out/merged.txt\")\n",
    "\n",
    "char_input = input.copy()\n",
    "tokenized_word_input = input.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ea445b55fce03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"vocab size: \", bpe.vocab_size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
