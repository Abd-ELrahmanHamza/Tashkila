{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c9d7979107b69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d06c7f266dbef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T21:45:14.191791500Z",
     "start_time": "2023-12-09T21:45:14.133792500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8879b5a840b7f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a06d932a5f623e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T21:45:14.192790Z",
     "start_time": "2023-12-09T21:45:14.152801Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, dropout_probability):\n",
    "        super().__init__()\n",
    "        # TODO: replace with one hot encoding\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm_layer = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout_probability)\n",
    "\n",
    "        # Dropout layer to prevent over fitting (regularization)\n",
    "        # it randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\n",
    "        self.dropout = nn.Dropout(dropout_probability)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs = [inputs len, batch size]\n",
    "        embeddings = self.dropout(self.embedding(inputs))\n",
    "\n",
    "        # embedded = [inputs len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.lstm_layer(embeddings)\n",
    "\n",
    "        # outputs = [inputs len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cd3fa6b68bdc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "    def forward(self, x, h0, c0):\n",
    "        # print(\"from decoder forward\")\n",
    "        # print(x.shape)\n",
    "        embeddings = self.embedding(x).to(self.device)\n",
    "        # print(\"from decoder forward after embedding\")\n",
    "        # print(embeddings.shape)\n",
    "        h, (hn, cn) = self.rnn(embeddings, (h0, c0))\n",
    "        # h is the output of the RNN\n",
    "        # hn is the hidden state of the last timestep\n",
    "        # cn is the cell state of the last timestep\n",
    "        out = self.fc(h)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a16e4d343a2b13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Seq2Seq"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5b1c73c59363731c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, encoder_inputs, decoder_inputs):\n",
    "        encoder_hidden, encoder_cell = self.encoder(encoder_inputs)\n",
    "        decoder_output = self.decoder(decoder_inputs, encoder_hidden, encoder_cell)\n",
    "        return decoder_output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ff0370c64abd4a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125423347cfa284b",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from byte_pair_encoding import Byte_Pair_Encoding\n",
    "from letters_dataset import read_data, find_width_99_percentile\n",
    "\n",
    "input, expected_output = read_data(\"./clean_out/X.csv\", \"./clean_out/Y.csv\", True)\n",
    "print(input[0])\n",
    "# Find the max sentence length\n",
    "max_sentence_length = find_width_99_percentile(input)\n",
    "\n",
    "bpe = Byte_Pair_Encoding(max_sentence_length)\n",
    "bpe.train(\"./clean_out/merged.txt\")\n",
    "\n",
    "char_input = input.copy()\n",
    "tokenized_word_input = input.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"vocab size: \", bpe.vocab_size())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478ea445b55fce03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
